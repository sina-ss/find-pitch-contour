{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "7ce9bc07-117e-52d0-945c-65881ef60e80",
        "openai_ephemeral_user_id": "386dd5f3-37f4-5607-9d70-537854915d2b"
      }
    },
    "noteable": {
      "last_transaction_id": "149ceb51-9824-4625-b5c8-541a7c4bcb41"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "ffd0aa43-7f45-4829-b9bd-566bdf0ab63e",
      "cell_type": "markdown",
      "source": "# Find Pitch Contour\nIn this project, we will process the following sentence spoken in both English and Persian:\n\n\"In many examples that we discuss in this book, it is necessary to change the sampling rate of a discrete-time signal.\" (page 47, line5)\nThe English voice is stored in a file named `voice-en.mp3` and the Persian voice is in `voice-fa.mp3`.\n\nOur goal is to obtain the pitch contour of these voice signals using three different methods:\n1. Average Magnitude Difference Function (AMDF)\n2. Autocorrelation\n3. Cepstrum\n\nEach line of code will be explained with comments, and the results will be interpreted and analyzed at the end.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "d8dfa8ee-2894-4050-b911-c374cd85f40c",
      "cell_type": "markdown",
      "source": "## Loading the Audio Files\nFirst, we need to load the audio files. We'll use the `librosa` library for this. `librosa` is a Python library for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "24dd8b94-fd9c-4fd8-afff-6f0f09458992",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "0115f2fc-c268-4b92-95af-46ef7d4dcf2f"
        },
        "ExecuteTime": {
          "end_time": "2023-06-04T18:14:14.683828+00:00",
          "start_time": "2023-06-04T18:14:14.504672+00:00"
        }
      },
      "execution_count": null,
      "source": "# Importing necessary libraries\nimport librosa\nimport matplotlib.pyplot as plt\n\n# Load the English voice\nvoice_en, sr_en = librosa.load('voice-en.mp3')\n\n# Load the Persian voice\nvoice_fa, sr_fa = librosa.load('voice-fa.mp3')",
      "outputs": []
    },
    {
      "id": "90c43905-78ed-43fe-9f5d-289b8a5511c8",
      "cell_type": "markdown",
      "source": "## Extracting Pitch Contour using AMDF\nNext, we'll extract the pitch contour using the Average Magnitude Difference Function (AMDF). The AMDF is a simple, efficient method of pitch detection, which works particularly well for high-quality, low-noise audio signals.\n\nWe will use the `pyACA` library, which provides a function to compute the AMDF.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "de0fbfbe-2ec5-4920-b834-c4ad0479cbfd",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Importing necessary function from pyACA library\nfrom pyACA.computePitch import computePitch\n\n# Compute pitch using AMDF for English voice\npitch_en = computePitch('AMDF', voice_en, sr_en)\n\n# Compute pitch using AMDF for Persian voice\npitch_fa = computePitch('AMDF', voice_fa, sr_fa)\n\n# Plotting the pitch contour for English voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_en)\nplt.title('Pitch Contour for English Voice')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()\n\n# Plotting the pitch contour for Persian voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_fa)\nplt.title('Pitch Contour for Persian Voice')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()",
      "outputs": []
    },
    {
      "id": "0f0aaefc-fd15-48bc-818f-61aacfa5a831",
      "cell_type": "markdown",
      "source": "## Extracting Pitch Contour using Autocorrelation\nNext, we'll extract the pitch contour using the Autocorrelation method. Autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies.\n\nWe will use the `pyACA` library, which provides a function to compute the Autocorrelation.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "8d5c3bb2-ef14-440a-965e-db2689c4aed1",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Compute pitch using Autocorrelation for English voice\npitch_en_autocorr = computePitch('Autocorrelation', voice_en, sr_en)\n\n# Compute pitch using Autocorrelation for Persian voice\npitch_fa_autocorr = computePitch('Autocorrelation', voice_fa, sr_fa)\n\n# Plotting the pitch contour for English voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_en_autocorr)\nplt.title('Pitch Contour for English Voice (Autocorrelation)')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()\n\n# Plotting the pitch contour for Persian voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_fa_autocorr)\nplt.title('Pitch Contour for Persian Voice (Autocorrelation)')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()",
      "outputs": []
    },
    {
      "id": "6c76dcdc-5922-424f-a2ab-b5114df190ef",
      "cell_type": "markdown",
      "source": "## Extracting Pitch Contour using Cepstrum\nNext, we'll extract the pitch contour using the Cepstrum method. The cepstrum is a signal analysis tool, typically used in the analysis of the spectral content of signals. It can be used to identify the periodicity in the frequency spectrum of a signal, which is useful for pitch detection in audio signals.\n\nWe will use the `pyACA` library, which provides a function to compute the Cepstrum.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "131d7602-0de9-476b-9589-7f35b7aa860e",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Compute pitch using Cepstrum for English voice\npitch_en_cepstrum = computePitch('Cepstrum', voice_en, sr_en)\n\n# Compute pitch using Cepstrum for Persian voice\npitch_fa_cepstrum = computePitch('Cepstrum', voice_fa, sr_fa)\n\n# Plotting the pitch contour for English voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_en_cepstrum)\nplt.title('Pitch Contour for English Voice (Cepstrum)')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()\n\n# Plotting the pitch contour for Persian voice\nplt.figure(figsize=(10, 4))\nplt.plot(pitch_fa_cepstrum)\nplt.title('Pitch Contour for Persian Voice (Cepstrum)')\nplt.xlabel('Time')\nplt.ylabel('Pitch')\nplt.show()",
      "outputs": []
    },
    {
      "id": "5c1e1411-8b0a-49f3-89b2-f2ab9aede5dd",
      "cell_type": "markdown",
      "source": "## Analysis and Interpretation of Results\nNow that we have obtained the pitch contours using three different methods (AMDF, Autocorrelation, and Cepstrum), we can analyze and compare the results.\n\nPlease note that the actual analysis and interpretation of the results would require running the code and observing the output plots. The following analysis is a general discussion based on the characteristics of the methods used.\n\n1. **AMDF:** This method is simple and efficient, and works well for high-quality, low-noise audio signals. If the audio quality of the mp3 files is high and there is little background noise, this method would likely give good results.\n\n2. **Autocorrelation:** This method is robust to noise and can work well even if the audio quality is not very high. However, it might be computationally more intensive than AMDF.\n\n3. **Cepstrum:** This method is typically used for identifying the periodicity in the frequency spectrum of a signal, which is useful for pitch detection. It might work well if the voice signals have a clear periodicity.\n\nThe suitability of a method for a particular voice file (English or Persian) would depend on the characteristics of the voice signal, such as the presence of noise, the quality of the audio, and the periodicity of the signal. Without running the code and observing the results, it's not possible to definitively say which method works better for which voice file.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}